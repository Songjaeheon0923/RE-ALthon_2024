{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKeCEP2b5tLyUz4egB0IQe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Songjaeheon0923/RE-ALthon_2024/blob/main/AI_model1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet  langchain-google-genai pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vri4vNXt5WPM",
        "outputId": "8f0e8ebb-0028-463b-a75b-1034f1834378",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
        "import torch\n",
        "import librosa\n",
        "\n",
        "# 1. 한국어 모델과 프로세서 로드\n",
        "processor = Wav2Vec2Processor.from_pretrained(\"kresnik/wav2vec2-large-xlsr-korean\")\n",
        "model = Wav2Vec2ForCTC.from_pretrained(\"kresnik/wav2vec2-large-xlsr-korean\")\n",
        "\n",
        "# 2. 음성을 텍스트로 변환하는 함수\n",
        "def speech_to_text(audio_path):\n",
        "    # 2-1. 오디오 파일 로드\n",
        "    audio, sr = librosa.load(audio_path, sr=16000)  # 샘플링 레이트 16kHz로 맞춤\n",
        "\n",
        "    # 2-2. 모델 입력 데이터 생성\n",
        "    input_values = processor(audio, sampling_rate=sr, return_tensors=\"pt\", padding=True).input_values\n",
        "\n",
        "    # 2-3. 모델 예측\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_values).logits\n",
        "\n",
        "    # 2-4. 텍스트 디코딩\n",
        "    predicted_ids = torch.argmax(logits, dim=-1)\n",
        "    transcription = processor.batch_decode(predicted_ids)[0]\n",
        "    return transcription\n",
        "\n",
        "# 3. 텍스트 정규화 함수\n",
        "def normalize_text(text):\n",
        "     corrections = {\n",
        "         \"스소은\": \"해커톤은\",\n",
        "     }\n",
        "     for wrong, correct in corrections.items():\n",
        "         text = text.replace(wrong, correct)\n",
        "     return text\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    audio_file = \"/content/해커톤은재미있다.m4a\"  # 처리할 오디오 파일 경로\n",
        "\n",
        "    # 음성 텍스트 변환\n",
        "    raw_result = speech_to_text(audio_file)\n",
        "\n",
        "    # 텍스트 정규화\n",
        "    processed_result = normalize_text(raw_result)\n",
        "\n",
        "    print(processed_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bnjaEyM-R48",
        "outputId": "2f11a055-fce1-41ff-f736-f9dd20444f60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-ee20c9da3c8d>:12: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sr = librosa.load(audio_path, sr=16000)  # 샘플링 레이트 16kHz로 맞춤\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "해사터은 재미 있다\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "API_KEY = 'AIzaSyDJe68pRn5j9MLo2vQp76SBEKP-IFEFpkc'"
      ],
      "metadata": {
        "id": "98sD-GiH_AMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# LLM 인스턴스 생성\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    api_key=API_KEY,\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    temperature=0.7\n",
        ")"
      ],
      "metadata": {
        "id": "B28O-NcY_iqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import itemgetter\n",
        "from langchain.schema import StrOutputParser\n",
        "# from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
        "# from langchain.chat_models import ChatGooglePalm\n",
        "\n",
        "from langchain.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    MessagesPlaceholder,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate\n",
        ")"
      ],
      "metadata": {
        "id": "sb5mGWn0_lyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### EDIT HERE ###\n",
        "prompt1 = ChatPromptTemplate.from_template(\n",
        "    '''이 모델은 어눌한 한국어 발음을 기반으로 올바른 발음이 뭘지 추측하는 일을 해\n",
        "    {raw_tts}을 입력으로 받았을 때, 올바른 문장이 무엇일지 추측해줘\n",
        "    출력으로는 반드시 해당 문장만을 출력해줘'''\n",
        ")\n",
        "chain1 = (prompt1\n",
        "  | llm\n",
        "  | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "4FHPFf7g_nri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt2 = ChatPromptTemplate.from_template(\n",
        "    \"\"\"이 모델은 한국어 발음 교정에 대해 전문적인 답변을 제공합니다. 당신은 틀린 음절을 찾고 해당 음절에 대하여 어떻게 수정해야 하는지 답변해야 합니다.\n",
        "\n",
        "     {right_sentence}를 {raw_tts}로 발음했을 때 어떻게 개선하면 좋을지 알려줘\n",
        "\n",
        "      다음과 같은 json schema를 사용해줘\n",
        "\n",
        "        \"올바른 문장\": str,\n",
        "        \"tts 문장\": str,\n",
        "        \"틀린 음절\": [\n",
        "          \"음절1\": str,\n",
        "          \"발음 수정\": str,\n",
        "          \"개선 방법\": str\n",
        "           ],\n",
        "           \"음절2\": [\n",
        "              ...\n",
        "           ]\n",
        "        ]\n",
        "\n",
        "\n",
        "      발음 수정으로는 각 음절 별로 발음 오류를 수정하고 그 결과를 출력해줘\n",
        "      개선 방법으로는 이를 개선하기 위해 입모양 및 혀모양을 어떻게 해야 하는지 알려줘\n",
        "      \"\"\"\n",
        "\n",
        ")\n",
        "# chain2 정의\n",
        "chain2 = (\n",
        "    {\"right_sentence\": itemgetter(\"right_sentence\"), \"raw_tts\": itemgetter(\"raw_tts\")}\n",
        "    | prompt2\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "20O9gLDP_pfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def pronunciation_correction(input_data) -> str:\n",
        "    right_sentence_value = input_data.get(\"right_sentence\")\n",
        "\n",
        "    if right_sentence_value is None:\n",
        "        right_sentence_value = chain1.invoke({\"raw_tts\": input_data[\"raw_tts\"]})\n",
        "\n",
        "    max_attempts = 5\n",
        "    attempt = 0\n",
        "    result_json = None\n",
        "\n",
        "    while attempt < max_attempts:\n",
        "        # chain2 호출\n",
        "        response = chain2.invoke({\n",
        "            \"raw_tts\": input_data[\"raw_tts\"],\n",
        "            \"right_sentence\": right_sentence_value\n",
        "        })\n",
        "\n",
        "        # 불필요한 ```json과 ``` 제거\n",
        "        result = response.replace(\"```json\", \"\").replace(\"```\", \"\")\n",
        "\n",
        "        # JSON 변환 시도\n",
        "        try:\n",
        "            result_json = json.loads(result)\n",
        "            return result\n",
        "        except json.JSONDecodeError:\n",
        "            attempt += 1\n",
        "            continue\n",
        "\n",
        "    return {\"error\": \"Invalid JSON format after 3 attempts\"}\n",
        "\n",
        "\n",
        "json_data = {\"raw_tts\": processed_result, \"right_sentence\": \"나는 학교에 가고 싶어\" }\n",
        "\n",
        "result = pronunciation_correction(json_data)\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUfUkfOQ_rE_",
        "outputId": "17c688c6-6c68-450d-89fb-2e050b1aaf9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "{\n",
            "  \"올바른 문장\": \"나는 학교에 가고 싶어\",\n",
            "  \"tts 문장\": \"해사터은 재미있다\",\n",
            "  \"틀린 음절\": [\n",
            "    {\n",
            "      \"음절1\": \"해\",\n",
            "      \"발음 수정\": \"나\",\n",
            "      \"개선 방법\": \"입술을 살짝 벌리고 혀의 앞쪽을 살짝 올려 '나' 소리를 냅니다. '해'는 입술을 둥글게 모으는 소리이므로, 입술 모양을 바꾸는 것이 중요합니다.\"\n",
            "    },\n",
            "    {\n",
            "      \"음절2\": \"사\",\n",
            "      \"발음 수정\": \"학\",\n",
            "      \"개선 방법\": \"혀의 중간 부분을 입천장 가까이 올려 '학' 소리를 냅니다. '사'는 혀의 앞쪽을 치아 가까이 대고 발음하는 소리이므로, 혀의 위치를 뒤로 이동시켜야 합니다. 입술은 자연스럽게 벌어져야 합니다.\"\n",
            "    },\n",
            "    {\n",
            "      \"음절3\": \"터\",\n",
            "      \"발음 수정\": \"교\",\n",
            "      \"개선 방법\": \"'교'는 혀의 중간 부분을 입천장에 가볍게 대고 'ㄱ' 소리를 낸 후, 혀를 살짝 내려 '요' 소리를 냅니다. '터'는 혀끝을 입천장에 대고 발음하는 소리이므로, 혀의 위치를 조절하고 입술을 살짝 둥글게 해야 합니다.\"\n",
            "    },\n",
            "    {\n",
            "      \"음절4\": \"은\",\n",
            "      \"발음 수정\": \"에\",\n",
            "      \"개선 방법\": \"'에'는 입을 살짝 벌리고 혀를 평평하게 유지하며 발음합니다. '은'은 혀의 중간 부분을 입천장 가까이 올려 발음하는 소리이므로, 혀의 위치를 아래로 내려야 합니다.\"\n",
            "    },\n",
            "    {\n",
            "      \"음절5\": \"재\",\n",
            "      \"발음 수정\": \"가\",\n",
            "      \"개선 방법\": \"'가'는 입을 벌리고 혀의 뒷부분을 살짝 올려 발음합니다. '재'는 혀의 앞쪽을 치아 가까이 대고 발음하는 소리이므로, 혀의 위치를 뒤로 이동시켜야 합니다.\"\n",
            "    },\n",
            "    {\n",
            "      \"음절6\": \"미\",\n",
            "      \"발음 수정\": \"고\",\n",
            "      \"개선 방법\": \"'고'는 입을 벌리고 혀의 뒷부분을 입천장에 가볍게 대고 발음합니다. '미'는 입술을 살짝 내밀고 발음하는 소리이므로, 입술 모양을 바꾸고 혀의 위치를 조절해야 합니다.\"\n",
            "    },\n",
            "    {\n",
            "      \"음절7\": \"있\",\n",
            "      \"발음 수정\": \"싶\",\n",
            "      \"개선 방법\": \"'싶'은 'ㅅ' 발음을 정확하게 하고 입술을 살짝 오므려 '입' 소리를 냅니다. '있'은 혀의 위치가 다르므로 혀의 위치를 조절하고 입술 모양을 바꾸어야 합니다.\"\n",
            "    },\n",
            "    {\n",
            "      \"음절8\": \"다\",\n",
            "      \"발음 수정\": \"어\",\n",
            "      \"개선 방법\": \"'어'는 입을 벌리고 혀를 평평하게 유지하며 발음합니다. '다'는 혀끝을 입천장에 가볍게 대고 발음하는 소리이므로, 혀의 위치를 조절해야 합니다.\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yKSBENjP_uVx"
      }
    }
  ]
}